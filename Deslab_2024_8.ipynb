{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnnguyen/DESLab_ML_training_2024/blob/main/Deslab_2024_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression in Scikit-Learn"
      ],
      "metadata": {
        "id": "v_qbZbRwicBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "# This line splits dataset into features and values\n",
        "X, y = df[df.columns[:-1]].values.astype(float), df[df.columns[-1]].values.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "# my model training is done and my model is ready to test!\n",
        "\n",
        "score = clf.score(X_test, y_test)\n",
        "# --- i have now tested my algorithm!\n",
        "print(f\"The accuracy for LogisticRegression is: {score * 100}%\")\n"
      ],
      "metadata": {
        "id": "BCq2gaztkm65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ chúng ta hãy xem xét các hệ số của mô hình đã học của chúng ta.\n",
        "\n",
        "Thật may mắn cho chúng ta, `clf.coef_` trực tiếp cung cấp cho chúng ta các hệ số!"
      ],
      "metadata": {
        "id": "gG1onkgmZf7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.coef_, clf.intercept_"
      ],
      "metadata": {
        "id": "ohP1mJ5HZoPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vì chúng ta có 3 lớp nên về mặt kỹ thuật chúng ta có 3 bộ phân loại, một bộ phân loại cho mỗi lớp. Các hệ số liên quan đến các đặc điểm của lớp, trong khi các điểm chặn là các hằng số đã học là một phần của bộ phân loại."
      ],
      "metadata": {
        "id": "e_QyCQq8Z6Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def get_probability(x, weights, intercept):\n",
        "    return sigmoid(np.sum(x * weights) + intercept)\n"
      ],
      "metadata": {
        "id": "5q0_pNfHaWDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ở đây chúng ta đã thiết kế hàm sigmoid chuyển đổi đầu ra của các trọng số phân loại của chúng ta thành xác suất.\n",
        "\n",
        "Sau đó, chúng ta có một hàm có thể nhận một tập hợp trọng số và một điểm và nhận được đầu ra `f(x) = wx + c`\n",
        "\n",
        "Hãy áp dụng điều này cho một điểm dữ liệu mẫu"
      ],
      "metadata": {
        "id": "NFm6IVcRbe4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt = X[120]\n",
        "print(f\"True label of this point is: {y[120]}\")\n",
        "for i in range(len(clf.coef_)):\n",
        "    print(f\"Output probability of classifier {i+1} (class = {i}) is: {get_probability(pt, clf.coef_[i], clf.intercept_[i]) * 100}%\")\n",
        "\n",
        "clf.predict([pt])"
      ],
      "metadata": {
        "id": "pgZPHTWTbwPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
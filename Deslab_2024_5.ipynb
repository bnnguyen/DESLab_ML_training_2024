{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnnguyen/DESLab_ML_training_2024/blob/main/Deslab_2024_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTlHPHWcH1n"
      },
      "source": [
        "#KNN - project m·∫´u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce597QuJOkT"
      },
      "source": [
        "Tr∆∞·ªõc h·∫øt, h√£y hi·ªÉu s∆° qua v·ªÅ thu·∫≠t to√°n kNN t·∫°i [ƒë√¢y](https://www.youtube.com/watch?v=0p0o5cmgLdE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Cc603OWvR4"
      },
      "source": [
        "Trong project n√†y, ch√∫ng ta s·∫Ω l√†m vi·ªác v·ªõi b·ªô d·ªØ li·ªáu Iris, m·ªôt b·ªô d·ªØ li·ªáu c√≥ s·∫µn trong th∆∞ vi·ªán sklearn.\n",
        "\n",
        "B·ªô d·ªØ li·ªáu Iris ch·ª©a b·ªën ƒë·∫∑c ƒëi·ªÉm (chi·ªÅu d√†i v√† chi·ªÅu r·ªông c·ªßa l√° ƒë√†i v√† c√°nh hoa) c·ªßa 50 m·∫´u c·ªßa ba lo√†i Iris (Iris setosa, Iris virginica v√† Iris versicolor). V√† ·ªü ƒë√¢y, ch√∫ng ta s·∫Ω t·∫°o ra m·ªôt m√¥ h√¨nh KNN ph√¢n ƒë·ªÉ ph√¢n lo·∫°i (d√°n nh√£n/ph√¢n nh√£n) c√°c lo√†i."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5njBpCXccnMW"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhv83Mladxyv"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create a DataFrame from the Iris data\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add the target column to the DataFrame\n",
        "iris_df['target'] = iris.target\n",
        "\n",
        "# Create a dictionary to map the target values to class names\n",
        "target_names = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "\n",
        "# Use the map function to replace the target values with class names\n",
        "iris_df['target'] = iris_df['target'].map(target_names)\n",
        "\n",
        "columns_to_display = iris_df.columns[:5]\n",
        "\n",
        "# Use the pd.concat() function to concatenate the first 5 columns of the DataFrame\n",
        "display(pd.concat([iris_df[col] for col in columns_to_display], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGI_wismhBU_"
      },
      "source": [
        "Ch√†, nh·ªØng b√†i tr∆∞·ªõc v√† b√†i n√†y ƒë·ªÅu l√† r·∫•t nhi·ªÅu code ƒë·∫•y. Ph·∫ßn code b√™n tr√™n c≈©ng c√≥ h∆°i \"ƒë·ªì s·ªô\", nh∆∞ng ƒë·ª´ng n·∫£n l√≤ng nh√©! Vi·ªác ch√∫ng ta ƒëang t·∫≠p trung l√†m b√¢y gi·ªù l√† hi·ªÉn th·ªã d·ªØ li·ªáu ·ªü d·∫°ng c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c ƒë·ªÉ ch√∫ng ta c√≥ th·ªÉ thao t√°c v√† l√†m vi·ªác tr√™n n√≥.\n",
        "\n",
        "Trong bi·ªÉu di·ªÖn DataFrame ·ªü tr√™n, b·∫°n c√≥ th·ªÉ th·∫•y r·∫±ng 4 c·ªôt ƒë·∫ßu ti√™n l√† s·ªë li·ªáu ƒëo l∆∞·ªùng c√°c ƒë·∫∑c ƒëi·ªÉm v√† c·ªôt cu·ªëi c√πng l√† ph√¢n lo·∫°i (nh√£n) c·ªßa c√° th·ªÉ mang c√°c ƒë·∫∑c ƒëi·ªÉm ƒë√≥!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7YhFdUShqU-"
      },
      "source": [
        "...nh∆∞ng, v·∫´n c√≤n nhi·ªÅu s·ªë qu√° ta! Hay bi·ªÉu di·ªÖn b·ªô d·ªØ li·ªáu b·∫±ng bi·ªÉu ƒë·ªì c√≥ s·ª± ph√¢n bi·ªát gi·ªØa c√°c lo√†i hoa xem sao?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FzGkR9NheMa"
      },
      "outputs": [],
      "source": [
        "def plot_iris_features(data):\n",
        "    # Get the feature and label arrays\n",
        "\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    feature_names = data.feature_names\n",
        "    # Create a list of colors for each class\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    # Create a list of the indices of each class\n",
        "    class_indices = [np.where(y == i) for i in range(3)]\n",
        "    # Create a list of all possible combinations of 2 features\n",
        "    feature_combinations = [(i, j) for i in range(4) for j in range(i+1, 4)]\n",
        "    # Create a subplot for each combination of 2 features\n",
        "    for i, (x_index, y_index) in enumerate(feature_combinations):\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        for class_index, color in zip(class_indices, colors):\n",
        "            plt.scatter(X[class_index, x_index], X[class_index, y_index], c=color)\n",
        "        plt.xlabel(feature_names[x_index])\n",
        "        plt.ylabel(feature_names[y_index])\n",
        "        plt.tight_layout()\n",
        "\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gly-SGbfh4iA"
      },
      "source": [
        "H√†m n√†y s·∫Ω gi√∫p ch√∫ng ta v·∫Ω m·ªôt s·ªë bi·ªÉu ƒë·ªì v√† cho ch√∫ng ta th·∫•y m·ªëi quan h·ªá gi·ªØa c√°c ƒë·∫∑c ƒëi·ªÉm c·ªßa d·ªØ li·ªáu v√† nh√£n c·ªßa ch√∫ng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5j4fLgah4Mf"
      },
      "outputs": [],
      "source": [
        "all_plots = plot_iris_features(iris)\n",
        "all_plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aV_LhfFip4x"
      },
      "source": [
        "Bi·ªÉu ƒë·ªì c·ªßa ch√∫ng ta cho th·∫•y ƒëi·ªÅu g√¨? M·ªói bi·ªÉu ƒë·ªì trong s·ªë 6 bi·ªÉu ƒë·ªì ch·ªçn c√πng l√∫c 2 ƒë·∫∑c ƒëi·ªÉm v√† sau ƒë√≥ bi·ªÉu di·ªÖn ƒëo l∆∞·ªùng 2 ƒë·∫∑c ƒëi·ªÉm ƒë√≥ c·ªßa t·∫•t c·∫£ 50 m·∫´u hoa tr√™n bi·ªÉu ƒë·ªì 2D. Ch√∫ng ta ƒëi tr∆∞·ªõc m·ªôt b∆∞·ªõc v√† t√¥ m√†u ƒëi·ªÉm c·ªßa m·ªói lo√†i hoa b·∫±ng nh·ªØng m√†u kh√°c nhau.\n",
        "\n",
        "B·∫°n ƒë√£ c√≥ th·ªÉ nh√¨n th·∫•y l·ª£i √≠ch c·ªßa vi·ªác v·∫Ω ra bi·ªÉu ƒë·ªì. Th√¥ng qua k·ªπ thu·∫≠t n√†y, ch√∫ng ta ƒë√£ c√≥ h√¨nh dung chung v·ªÅ m·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm:\n",
        "\n",
        "\n",
        "\n",
        "* D·ªØ li·ªáu n√†y c√≥ th·ªÉ ph√¢n t√°ch r√µ r√†ng (m·ªói lo√†i hoa c√≥ m·ªôt gi·ªõi h·∫°n chi·ªÅu d√†i c≈©ng nh∆∞ l√† chi·ªÅu r·ªông c√°nh hoa, ƒë√†i hoa ri√™ng). ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† v·∫•n ƒë·ªÅ ph√¢n lo·∫°i v·ªõi b·ªô d·ªØ li·ªáu n√†y kh√¥ng ph·∫£i l√† kh√¥ng th·ªÉ gi·∫£i quy·∫øt ƒë∆∞·ª£c.\n",
        "* M·ªôt s·ªë t·ªï h·ª£p c√°c ƒë·∫∑c ƒëi·ªÉm (nh∆∞ chi·ªÅu d√†i c√°nh hoa v√† chi·ªÅu d√†i ƒë√†i hoa) l√† s·ª± k·∫øt h·ª£p t·ªët ƒë·ªÉ ph√¢n bi·ªát c√°c lo√†i hoa kh√°c nhau (v√¨ c√°c ƒë·∫∑c ƒëi·ªÉm n√†y c√≥ s·ª± ch√™nh l·ªách r·∫•t r√µ r√†ng/l·ªõn gi·ªØa nh·ªØng lo√†i hoa kh√°c nhau). Nh·ªØng s·ª± k·∫øt h·ª£p kh√°c kh√°c th√¨ kh√¥ng..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nttR-9OMtXk"
      },
      "source": [
        "B√¢y gi·ªù h√£y ti·∫øp t·ª•c v√† tri·ªÉn khai KNN.\n",
        "\n",
        "ƒê·∫ßu ti√™n ch√∫ng ta b·∫Øt ƒë·∫ßu v·ªõi m·ªôt class. Class l√† ƒë∆°n v·ªã logic c·ªßa ch∆∞∆°ng tr√¨nh Python (ho·∫∑c b·∫•t k·ª≥ ng√¥n ng·ªØ n√†o). M·ªôt class x√°c ƒë·ªãnh c·∫•u tr√∫c cho ƒë∆°n v·ªã logic n√†y. M·ªói s·ª± kh·ªüi t·∫°o ri√™ng l·∫ª c·ªßa class ƒë∆∞·ª£c g·ªçi l√† m·ªôt unit.\n",
        "\n",
        "M·ªôt unit c·ªßa class th∆∞·ªùng ch·ª©a m·ªôt s·ªë gi√° tr·ªã d·ªØ li·ªáu c·ª• th·ªÉ cho unit ƒë√≥. T·∫•t c·∫£ c√°c bi·∫øn `self.something` ƒë·ªÅu c√≥ nghƒ©a l√† ch√∫ng l√† thu·ªôc t√≠nh d·ªØ li·ªáu c·ªßa ri√™ng m·ªôt class.\n",
        "\n",
        "M·ªôt class c≈©ng ƒë·ªãnh nghƒ©a m·ªôt s·ªë h√†m c√≥ th·ªÉ nh·∫≠n m·ªôt s·ªë tham s·ªë b√™n ngo√†i v√† √°p d·ª•ng t√≠nh to√°n tr√™n nh·ªØng h√†m s·ª≠ d·ª•ng m·ªôt s·ªë d·ªØ li·ªáu m√† ch√∫ng c√≥.\n",
        "\n",
        "Tr∆∞·ªõc ti√™n, ch√∫ng ta x√°c ƒë·ªãnh m·ªôt class `KNeighborsClassifierCustom` s·∫Ω l√† class KNN. Vi·ªác n√†y ch·ªâ t√≠nh ƒë·∫øn m·ªôt tham s·ªë - gi√° tr·ªã c·ªßa `k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVTnrBxhLPAO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class KNeighborsClassifierCustom:\n",
        "    def __init__(self, n_neighbors):\n",
        "        self.n_neighbors = n_neighbors\n",
        "\n",
        "    # X is a list of multiple points!\n",
        "    # X could look like\n",
        "    # [[11, 22, 14],\n",
        "    #. [53, 36, 57],\n",
        "    #. [34, 22, 19]]\n",
        "    # For every point in X you will have a label. y could look like ['A', 'A', 'B']\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    # X is a list of multiple points!\n",
        "    # X could look like\n",
        "    # [[1, 2, 4],\n",
        "    #. [3, 6, 7],\n",
        "    #. [4, 2, 9]]\n",
        "    # This means you're asked to find the label of points (1, 2, 4), (3, 6, 7), (4, 2, 9)\n",
        "    # If there are 2 labels A and B, your example return y_pred_all could look like ['A', 'B', 'B']\n",
        "    def predict(self, X):\n",
        "        y_pred_all = []\n",
        "        for x_test in X:\n",
        "          distances = np.sqrt(np.sum((self.X_train - x_test)**2, axis=1))\n",
        "          nearest_indices = np.argsort(distances, axis=0)[:self.n_neighbors]\n",
        "          nearest_labels = self.y_train[nearest_indices]\n",
        "          (values,counts) = np.unique(nearest_labels, return_counts=True)\n",
        "          ind=np.argmax(counts)\n",
        "          y_pred_all.append(values[ind])\n",
        "        return y_pred_all\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRfcr9g-MdLe"
      },
      "source": [
        "Ti·∫øp theo ch√∫ng ta thi·∫øt k·∫ø m·ªôt h√†m ph√π h·ª£p. Th√¥ng th∆∞·ªùng, t·∫•t c·∫£ c√°c class d√†nh cho thu·∫≠t to√°n Machine Learning ƒë·ªÅu th·ª±c hi·ªán tr√≠ch xu·∫•t m·∫´u v√† ph√¢n t√≠ch d·ªØ li·ªáu t·∫°i h√†m n√†y. Nh∆∞ng h√£y nh·ªõ r·∫±ng trong KNN, ch√∫ng ta kh√¥ng tr√≠ch xu·∫•t b·∫•t k·ª≥ m·∫´u n√†o! Hay n√≥i ƒë√∫ng h∆°n, ch√∫ng ta ch·ªâ d√πng c√°c ƒëi·ªÉm ƒë∆∞·ª£c nh·∫≠p, kh√¥ng c·∫ßn qua x·ª≠ l√Ω to√°n h·ªçc, v√† s·ª≠ d·ª•ng ch√∫ng ƒë·ªÉ t√¨m nh·ªØng ƒëi·ªÉm l√¢n c·∫≠n g·∫ßn nh·∫•t c·ªßa b·∫•t k·ª≥ ƒëi·ªÉm n√†o m√† ch√∫ng ta ƒë∆∞·ª£c y√™u c·∫ßu ph√¢n lo·∫°i. Do ƒë√≥, h√†m `fit` c·ªßa ch√∫ng ta ch·ªâ l∆∞u tr·ªØ d·ªØ li·ªáu hu·∫•n luy·ªán ƒë∆∞·ª£c cung c·∫•p cho n√≥."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NeP9Q5fNt32"
      },
      "source": [
        "B√¢y gi·ªù l√† l√∫c thi·∫øt k·∫ø h√†m `predict` c·ªßa ch√∫ng ta. ƒê·ªëi v·ªõi m·ªói ƒëi·ªÉm trong X, ch√∫ng ta t√≠nh to√°n kho·∫£ng c√°ch c·ªßa n√≥ v·ªõi t·∫•t c·∫£ c√°c ƒëi·ªÉm trong `self.X_train`, sau ƒë√≥ ch·ªçn `n_neighbors` tr√™n c√πng v√† ki·ªÉm tra xem nh√£n c·ªßa ch√∫ng l√† g√¨. Sau ƒë√≥, ch√∫ng ta t√≠nh to√°n nh√£n n√†o xu·∫•t hi·ªán th∆∞·ªùng xuy√™n nh·∫•t v√† th√™m n√≥ v√†o danh s√°ch d·ª± ƒëo√°n c·ªßa ch√∫ng ta. Cu·ªëi c√πng ch√∫ng ta tr·∫£ l·∫°i t·∫•t c·∫£ c√°c d·ª± ƒëo√°n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMvrJ5APNJYO"
      },
      "source": [
        "Ph·∫ßn ti·∫øp theo l√† thi·∫øt k·∫ø h√†m `score`. V·ªõi m·ªôt s·ªë ƒëi·ªÉm d·ªØ li·ªáu (`X`) v√† nh√£n c·ªßa ch√∫ng (`y`), ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng thu·∫≠t to√°n d·ª± ƒëo√°n c·ªßa ri√™ng m√¨nh v√† ki·ªÉm tra xem n√≥ ch√≠nh x√°c ƒë·∫øn m·ª©c n√†o. V√¨ v·∫≠y, ch√∫ng ta chuy·ªÉn t·∫•t c·∫£ c√°c ƒëi·ªÉm cho h√†m `predict`, l·∫•y c√°c nh√£n ƒë∆∞·ª£c d·ª± ƒëo√°n v√† sau ƒë√≥ ph√©p so s√°nh `(y_pred == y)` cung c·∫•p cho ch√∫ng ta gi√° tr·ªã 0 ho·∫∑c 1. (0 cho m·ªói ƒëi·ªÉm ch√∫ng ta sai, 1 cho m·ªói ƒëi·ªÉm ch√∫ng ta ƒë√∫ng.) Ch√∫ng ta l·∫•y gi√° tr·ªã trung b√¨nh v√† g·ªçi ƒë√≥ l√† ƒë·ªô hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUJlqdfWRBFi"
      },
      "source": [
        "# Ki·ªÉm tra ƒë·ªô hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c t·∫°o ra v·ªõi KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS77-j-0TO9Z"
      },
      "source": [
        "Ch√∫ng ta c≈©ng mu·ªën so s√°nh xem gi√° tr·ªã n√†o c·ªßa `k` (s·ªë c·ª•m ph√¢n lo·∫°i nh√£n) mang l·∫°i cho ch√∫ng ta s·ªë l∆∞·ª£ng m·∫´u ƒë√∫ng t·ªëi ƒëa! C√°ch t·ªët nh·∫•t ƒë·ªÉ l√†m ƒëi·ªÅu n√†y l√† quan s√°t n√≥ - v√† ƒë√≥ ch√≠nh x√°c l√† nh·ªØng g√¨ ch√∫ng ta s·∫Ω l√†m.\n",
        "\n",
        "Khi b·∫°n c√≥ ƒë∆∞·ª£c ph·∫ßn trƒÉm ch√≠nh x√°c cho c√°c gi√° tr·ªã kh√°c nhau c·ªßa `k`, vi·ªác v·∫Ω th√¥ng tin ƒë√≥ d∆∞·ªõi d·∫°ng bi·ªÉu ƒë·ªì c·ªôt l√† kh√° ƒë∆°n gi·∫£n. B·∫°n ch·ªâ c·∫ßn x√°c ƒë·ªãnh nh·ªØng gi√° tr·ªã n√†o s·∫Ω n·∫±m tr√™n tr·ª•c X v√† c√°c gi√° tr·ªã t∆∞∆°ng ·ª©ng tr√™n tr·ª•c Y.\n",
        "\n",
        "Matplotlib cung c·∫•p cho ch√∫ng ta m·ªôt s·ªë h√†m h·ªØu √≠ch ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì c·ªôt m√† ch√∫ng ta ƒëang c·∫ßn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Z84pE3O1P2"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(accuracy_per_k, classifier_name):\n",
        "    # Extract the values of k and accuracy from the dictionary\n",
        "    k_values = list(accuracy_per_k.keys())\n",
        "    accuracy = list(accuracy_per_k.values())\n",
        "    # Create a bar chart of the accuracy per k\n",
        "    plt.bar(k_values, accuracy)\n",
        "    plt.xlabel(\"k\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"Accuracy of KNN per k for {classifier_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N16lxBteTbGj"
      },
      "source": [
        "B√¢y gi·ªù ch√∫ng ta ƒë√£ c√≥ t·∫•t c·∫£ c√°c h√†m c·∫ßn thi·∫øt - c√¥ng vi·ªác c·ªßa ch√∫ng ta g·∫ßn nh∆∞ ƒë√£ ho√†n th√†nh. T·∫•t c·∫£ nh·ªØng g√¨ c·∫ßn l√†m l√† m·ªôt h√†m c√≥ th·ªÉ ƒëi·ªÅn c√°c gi√° tr·ªã kh√°c nhau c·ªßa `k` ƒë·ªìng th·ªùi t√≠nh to√°n ƒë·ªô ch√≠nh x√°c tr√™n t·ª´ng gi√° tr·ªã c·ªßa `k`, r·ªìi cu·ªëi c√πng v·∫Ω bi·ªÉu ƒë·ªì c·ªôt b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c gi√° tr·ªã ƒë√≥."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTXcyM5eO5-q"
      },
      "outputs": [],
      "source": [
        "def find_best_k(X, y):\n",
        "    best_k = 0\n",
        "    best_accuracy = 0\n",
        "    accuracy_per_k = {}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "    for k in range(1, 11):\n",
        "        classifier = KNeighborsClassifierCustom(k)\n",
        "        classifier.fit(X_train, y_train)\n",
        "        accuracy_per_k[k] = classifier.score(X_test, y_test)\n",
        "        if accuracy_per_k[k] > best_accuracy:\n",
        "            best_k = k\n",
        "            best_accuracy = accuracy_per_k[k]\n",
        "    # call the plot_accuracy function\n",
        "    plot_accuracy(accuracy_per_k, \"Classifier\")\n",
        "    return best_k, best_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3K5gzXn9Kdo"
      },
      "source": [
        "C√πng xem k·∫øt qu·∫£ nh√©!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r_1HaDPPCy2"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "best_k, best_score = find_best_k(iris.data, iris.target)\n",
        "print(f\"The best value of k is {best_k} with accuracy {best_score * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_qbZbRwicBe"
      },
      "source": [
        "# Scikit-Learn\n",
        "\n",
        "Bi·∫øt c√°ch c√°c thu·∫≠t to√°n ƒë∆∞·ª£c tri·ªÉn khai l√† ƒëi·ªÅu tuy·ªát v·ªùi v√¨ n√≥ s·∫Ω gi√∫p b·∫°n gi·∫£i th√≠ch l√Ω do t·∫°i sao m·ªôt s·ªë thu·∫≠t to√°n ho·∫°t ƒë·ªông tr√™n d·ªØ li·ªáu c·ªßa b·∫°n.\n",
        "\n",
        "B√¢y gi·ªù, b·∫°n ƒë√£ bi·∫øt ch√≠nh x√°c thu·∫≠t to√°n *KNN* ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o. Tuy nhi√™n, ch√∫ng ta hi·∫øm khi t·ª± tri·ªÉn khai thu·∫≠t to√°n n√†y n√≥i ri√™ng, c≈©ng nh∆∞ c√°c thu·∫≠t to√°n Machine Learning n√≥i chung t·ª´ ƒë·∫ßu l·∫Øm ·∫•y ü§î, b·ªüi l·∫Ω ch√∫ng ta c√≥ s·ª± h·ªó tr·ª£ t·ª´ c√°c h√†m c√≥ s·∫µn trong th∆∞ vi·ªán Scikit-Learn.\n",
        "\n",
        "Scikit-learn l√† m·ªôt trong nh·ªØng th∆∞ vi·ªán m√°y h·ªçc ƒëang ph·ªï bi·∫øn nh·∫•t trong ng√†nh. V·ªõi s·ª± h·ªó tr·ª£ c·ªßa n√≥, b·∫°n s·∫Ω kh√¥ng c√≥ l·ªói kh√¥ng mong mu·ªën v√† c√≥ hi·ªáu su·∫•t c·ª±c k·ª≥ cao."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCq2gaztkm65"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def find_best_k_per_classifier(X, y):\n",
        "    best_k = {}\n",
        "    best_accuracy = {}\n",
        "    accuracy_per_k_per_classifier = {\"sklearn\": {}}  # Only include sklearn for now\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    for k in range(1, 11):\n",
        "        sklearn_classifier = KNeighborsClassifier(k)\n",
        "        sklearn_classifier.fit(X_train, y_train)\n",
        "        accuracy_per_k_per_classifier[\"sklearn\"][k] = sklearn_classifier.score(X_test, y_test)\n",
        "    plot_accuracy(accuracy_per_k_per_classifier[\"sklearn\"], \"SklearnKNN\")\n",
        "\n",
        "    return [max(accuracy_per_k_per_classifier.get(key, {}).items(), key=lambda x: x[1]) for key in accuracy_per_k_per_classifier.keys()]\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "accs_and_ks = find_best_k_per_classifier(iris.data, iris.target)\n",
        "\n",
        "print(f\"The best accuracy for Sklearn KNN is at k = {accs_and_ks[0][0]} with accuracy {accs_and_ks[0][1] * 100}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOaUmoMHgjn5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
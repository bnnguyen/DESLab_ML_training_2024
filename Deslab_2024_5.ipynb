{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnnguyen/DESLab_ML_training_2024/blob/main/Deslab_2024_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTlHPHWcH1n"
      },
      "source": [
        "#KNN - project mẫu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce597QuJOkT"
      },
      "source": [
        "Trước hết, hãy hiểu sơ qua về thuật toán kNN tại [đây](https://www.youtube.com/watch?v=0p0o5cmgLdE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Cc603OWvR4"
      },
      "source": [
        "Trong project này, chúng ta sẽ làm việc với bộ dữ liệu Iris, một bộ dữ liệu có sẵn trong thư viện sklearn.\n",
        "\n",
        "Bộ dữ liệu Iris chứa bốn đặc điểm (chiều dài và chiều rộng của lá đài và cánh hoa) của 50 mẫu của ba loài Iris (Iris setosa, Iris virginica và Iris versicolor). Và ở đây, chúng ta sẽ tạo ra một mô hình KNN phân để phân loại (dán nhãn/phân nhãn) các loài."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5njBpCXccnMW"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhv83Mladxyv"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create a DataFrame from the Iris data\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add the target column to the DataFrame\n",
        "iris_df['target'] = iris.target\n",
        "\n",
        "# Create a dictionary to map the target values to class names\n",
        "target_names = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "\n",
        "# Use the map function to replace the target values with class names\n",
        "iris_df['target'] = iris_df['target'].map(target_names)\n",
        "\n",
        "columns_to_display = iris_df.columns[:5]\n",
        "\n",
        "# Use the pd.concat() function to concatenate the first 5 columns of the DataFrame\n",
        "display(pd.concat([iris_df[col] for col in columns_to_display], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGI_wismhBU_"
      },
      "source": [
        "Chà, những bài trước và bài này đều là rất nhiều code đấy. Phần code bên trên cũng có hơi \"đồ sộ\", nhưng đừng nản lòng nhé! Việc chúng ta đang tập trung làm bây giờ là hiển thị dữ liệu ở dạng có thể đọc được để chúng ta có thể thao tác và làm việc trên nó.\n",
        "\n",
        "Trong biểu diễn DataFrame ở trên, bạn có thể thấy rằng 4 cột đầu tiên là số liệu đo lường các đặc điểm và cột cuối cùng là phân loại (nhãn) của cá thể mang các đặc điểm đó!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7YhFdUShqU-"
      },
      "source": [
        "...nhưng, vẫn còn nhiều số quá ta! Hay biểu diễn bộ dữ liệu bằng biểu đồ có sự phân biệt giữa các loài hoa xem sao?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FzGkR9NheMa"
      },
      "outputs": [],
      "source": [
        "def plot_iris_features(data):\n",
        "    # Get the feature and label arrays\n",
        "\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    feature_names = data.feature_names\n",
        "    # Create a list of colors for each class\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    # Create a list of the indices of each class\n",
        "    class_indices = [np.where(y == i) for i in range(3)]\n",
        "    # Create a list of all possible combinations of 2 features\n",
        "    feature_combinations = [(i, j) for i in range(4) for j in range(i+1, 4)]\n",
        "    # Create a subplot for each combination of 2 features\n",
        "    for i, (x_index, y_index) in enumerate(feature_combinations):\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        for class_index, color in zip(class_indices, colors):\n",
        "            plt.scatter(X[class_index, x_index], X[class_index, y_index], c=color)\n",
        "        plt.xlabel(feature_names[x_index])\n",
        "        plt.ylabel(feature_names[y_index])\n",
        "        plt.tight_layout()\n",
        "\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gly-SGbfh4iA"
      },
      "source": [
        "Hàm này sẽ giúp chúng ta vẽ một số biểu đồ và cho chúng ta thấy mối quan hệ giữa các đặc điểm của dữ liệu và nhãn của chúng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5j4fLgah4Mf"
      },
      "outputs": [],
      "source": [
        "all_plots = plot_iris_features(iris)\n",
        "all_plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aV_LhfFip4x"
      },
      "source": [
        "Biểu đồ của chúng ta cho thấy điều gì? Mỗi biểu đồ trong số 6 biểu đồ chọn cùng lúc 2 đặc điểm và sau đó biểu diễn đo lường 2 đặc điểm đó của tất cả 50 mẫu hoa trên biểu đồ 2D. Chúng ta đi trước một bước và tô màu điểm của mỗi loài hoa bằng những màu khác nhau.\n",
        "\n",
        "Bạn đã có thể nhìn thấy lợi ích của việc vẽ ra biểu đồ. Thông qua kỹ thuật này, chúng ta đã có hình dung chung về một số đặc điểm:\n",
        "\n",
        "\n",
        "\n",
        "* Dữ liệu này có thể phân tách rõ ràng (mỗi loài hoa có một giới hạn chiều dài cũng như là chiều rộng cánh hoa, đài hoa riêng). Điều này có nghĩa là vấn đề phân loại với bộ dữ liệu này không phải là không thể giải quyết được.\n",
        "* Một số tổ hợp các đặc điểm (như chiều dài cánh hoa và chiều dài đài hoa) là sự kết hợp tốt để phân biệt các loài hoa khác nhau (vì các đặc điểm này có sự chênh lệch rất rõ ràng/lớn giữa những loài hoa khác nhau). Những sự kết hợp khác khác thì không..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nttR-9OMtXk"
      },
      "source": [
        "Bây giờ hãy tiếp tục và triển khai KNN.\n",
        "\n",
        "Đầu tiên chúng ta bắt đầu với một class. Class là đơn vị logic của chương trình Python (hoặc bất kỳ ngôn ngữ nào). Một class xác định cấu trúc cho đơn vị logic này. Mỗi sự khởi tạo riêng lẻ của class được gọi là một unit.\n",
        "\n",
        "Một unit của class thường chứa một số giá trị dữ liệu cụ thể cho unit đó. Tất cả các biến `self.something` đều có nghĩa là chúng là thuộc tính dữ liệu của riêng một class.\n",
        "\n",
        "Một class cũng định nghĩa một số hàm có thể nhận một số tham số bên ngoài và áp dụng tính toán trên những hàm sử dụng một số dữ liệu mà chúng có.\n",
        "\n",
        "Trước tiên, chúng ta xác định một class `KNeighborsClassifierCustom` sẽ là class KNN. Việc này chỉ tính đến một tham số - giá trị của `k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVTnrBxhLPAO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class KNeighborsClassifierCustom:\n",
        "    def __init__(self, n_neighbors):\n",
        "        self.n_neighbors = n_neighbors\n",
        "\n",
        "    # X is a list of multiple points!\n",
        "    # X could look like\n",
        "    # [[11, 22, 14],\n",
        "    #. [53, 36, 57],\n",
        "    #. [34, 22, 19]]\n",
        "    # For every point in X you will have a label. y could look like ['A', 'A', 'B']\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    # X is a list of multiple points!\n",
        "    # X could look like\n",
        "    # [[1, 2, 4],\n",
        "    #. [3, 6, 7],\n",
        "    #. [4, 2, 9]]\n",
        "    # This means you're asked to find the label of points (1, 2, 4), (3, 6, 7), (4, 2, 9)\n",
        "    # If there are 2 labels A and B, your example return y_pred_all could look like ['A', 'B', 'B']\n",
        "    def predict(self, X):\n",
        "        y_pred_all = []\n",
        "        for x_test in X:\n",
        "          distances = np.sqrt(np.sum((self.X_train - x_test)**2, axis=1))\n",
        "          nearest_indices = np.argsort(distances, axis=0)[:self.n_neighbors]\n",
        "          nearest_labels = self.y_train[nearest_indices]\n",
        "          (values,counts) = np.unique(nearest_labels, return_counts=True)\n",
        "          ind=np.argmax(counts)\n",
        "          y_pred_all.append(values[ind])\n",
        "        return y_pred_all\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRfcr9g-MdLe"
      },
      "source": [
        "Tiếp theo chúng ta thiết kế một hàm phù hợp. Thông thường, tất cả các class dành cho thuật toán Machine Learning đều thực hiện trích xuất mẫu và phân tích dữ liệu tại hàm này. Nhưng hãy nhớ rằng trong KNN, chúng ta không trích xuất bất kỳ mẫu nào! Hay nói đúng hơn, chúng ta chỉ dùng các điểm được nhập, không cần qua xử lý toán học, và sử dụng chúng để tìm những điểm lân cận gần nhất của bất kỳ điểm nào mà chúng ta được yêu cầu phân loại. Do đó, hàm `fit` của chúng ta chỉ lưu trữ dữ liệu huấn luyện được cung cấp cho nó."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NeP9Q5fNt32"
      },
      "source": [
        "Bây giờ là lúc thiết kế hàm `predict` của chúng ta. Đối với mỗi điểm trong X, chúng ta tính toán khoảng cách của nó với tất cả các điểm trong `self.X_train`, sau đó chọn `n_neighbors` trên cùng và kiểm tra xem nhãn của chúng là gì. Sau đó, chúng ta tính toán nhãn nào xuất hiện thường xuyên nhất và thêm nó vào danh sách dự đoán của chúng ta. Cuối cùng chúng ta trả lại tất cả các dự đoán."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMvrJ5APNJYO"
      },
      "source": [
        "Phần tiếp theo là thiết kế hàm `score`. Với một số điểm dữ liệu (`X`) và nhãn của chúng (`y`), chúng ta có thể sử dụng thuật toán dự đoán của riêng mình và kiểm tra xem nó chính xác đến mức nào. Vì vậy, chúng ta chuyển tất cả các điểm cho hàm `predict`, lấy các nhãn được dự đoán và sau đó phép so sánh `(y_pred == y)` cung cấp cho chúng ta giá trị 0 hoặc 1. (0 cho mỗi điểm chúng ta sai, 1 cho mỗi điểm chúng ta đúng.) Chúng ta lấy giá trị trung bình và gọi đó là độ hiệu quả của mô hình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUJlqdfWRBFi"
      },
      "source": [
        "# Kiểm tra độ hiệu quả của mô hình được tạo ra với KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS77-j-0TO9Z"
      },
      "source": [
        "Chúng ta cũng muốn so sánh xem giá trị nào của `k` (số cụm phân loại nhãn) mang lại cho chúng ta số lượng mẫu đúng tối đa! Cách tốt nhất để làm điều này là quan sát nó - và đó chính xác là những gì chúng ta sẽ làm.\n",
        "\n",
        "Khi bạn có được phần trăm chính xác cho các giá trị khác nhau của `k`, việc vẽ thông tin đó dưới dạng biểu đồ cột là khá đơn giản. Bạn chỉ cần xác định những giá trị nào sẽ nằm trên trục X và các giá trị tương ứng trên trục Y.\n",
        "\n",
        "Matplotlib cung cấp cho chúng ta một số hàm hữu ích để vẽ biểu đồ cột mà chúng ta đang cần."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Z84pE3O1P2"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(accuracy_per_k, classifier_name):\n",
        "    # Extract the values of k and accuracy from the dictionary\n",
        "    k_values = list(accuracy_per_k.keys())\n",
        "    accuracy = list(accuracy_per_k.values())\n",
        "    # Create a bar chart of the accuracy per k\n",
        "    plt.bar(k_values, accuracy)\n",
        "    plt.xlabel(\"k\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"Accuracy of KNN per k for {classifier_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N16lxBteTbGj"
      },
      "source": [
        "Bây giờ chúng ta đã có tất cả các hàm cần thiết - công việc của chúng ta gần như đã hoàn thành. Tất cả những gì cần làm là một hàm có thể điền các giá trị khác nhau của `k` đồng thời tính toán độ chính xác trên từng giá trị của `k`, rồi cuối cùng vẽ biểu đồ cột bằng cách sử dụng các giá trị đó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTXcyM5eO5-q"
      },
      "outputs": [],
      "source": [
        "def find_best_k(X, y):\n",
        "    best_k = 0\n",
        "    best_accuracy = 0\n",
        "    accuracy_per_k = {}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "    for k in range(1, 11):\n",
        "        classifier = KNeighborsClassifierCustom(k)\n",
        "        classifier.fit(X_train, y_train)\n",
        "        accuracy_per_k[k] = classifier.score(X_test, y_test)\n",
        "        if accuracy_per_k[k] > best_accuracy:\n",
        "            best_k = k\n",
        "            best_accuracy = accuracy_per_k[k]\n",
        "    # call the plot_accuracy function\n",
        "    plot_accuracy(accuracy_per_k, \"Classifier\")\n",
        "    return best_k, best_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3K5gzXn9Kdo"
      },
      "source": [
        "Cùng xem kết quả nhé!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r_1HaDPPCy2"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "best_k, best_score = find_best_k(iris.data, iris.target)\n",
        "print(f\"The best value of k is {best_k} with accuracy {best_score * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_qbZbRwicBe"
      },
      "source": [
        "# Scikit-Learn\n",
        "\n",
        "Biết cách các thuật toán được triển khai là điều tuyệt vời vì nó sẽ giúp bạn giải thích lý do tại sao một số thuật toán hoạt động trên dữ liệu của bạn.\n",
        "\n",
        "Bây giờ, bạn đã biết chính xác thuật toán *KNN* hoạt động như thế nào. Tuy nhiên, chúng ta hiếm khi tự triển khai thuật toán này nói riêng, cũng như các thuật toán Machine Learning nói chung từ đầu lắm ấy 🤔, bởi lẽ chúng ta có sự hỗ trợ từ các hàm có sẵn trong thư viện Scikit-Learn.\n",
        "\n",
        "Scikit-learn là một trong những thư viện máy học đang phổ biến nhất trong ngành. Với sự hỗ trợ của nó, bạn sẽ không có lỗi không mong muốn và có hiệu suất cực kỳ cao."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCq2gaztkm65"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def find_best_k_per_classifier(X, y):\n",
        "    best_k = {}\n",
        "    best_accuracy = {}\n",
        "    accuracy_per_k_per_classifier = {\"sklearn\": {}}  # Only include sklearn for now\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    for k in range(1, 11):\n",
        "        sklearn_classifier = KNeighborsClassifier(k)\n",
        "        sklearn_classifier.fit(X_train, y_train)\n",
        "        accuracy_per_k_per_classifier[\"sklearn\"][k] = sklearn_classifier.score(X_test, y_test)\n",
        "    plot_accuracy(accuracy_per_k_per_classifier[\"sklearn\"], \"SklearnKNN\")\n",
        "\n",
        "    return [max(accuracy_per_k_per_classifier.get(key, {}).items(), key=lambda x: x[1]) for key in accuracy_per_k_per_classifier.keys()]\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "accs_and_ks = find_best_k_per_classifier(iris.data, iris.target)\n",
        "\n",
        "print(f\"The best accuracy for Sklearn KNN is at k = {accs_and_ks[0][0]} with accuracy {accs_and_ks[0][1] * 100}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOaUmoMHgjn5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}